{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import re\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///Messages.db')\n",
    "df = pd.read_sql(\"SELECT * FROM Messages\", engine)\n",
    "\n",
    "X = df['message']\n",
    "Y = df.drop(['id', 'message', 'original', 'genre'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"Normalize, tokenize and stem text string\n",
    "    \n",
    "    Args:\n",
    "    text: string. String containing message for processing\n",
    "       \n",
    "    Returns:\n",
    "    stemmed: list of strings. List containing normalized and stemmed word tokens\n",
    "    \"\"\"\n",
    "    # Convert text to lowercase and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "    \n",
    "    # Tokenize words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Stem word tokens and remove stop words\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    \n",
    "    stemmed = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(RandomForestClassifier()))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "           n_jobs=1))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)\n",
    "\n",
    "np.random.seed(17)\n",
    "pipeline.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_metrics(actual, predicted, col_names):\n",
    "    \"\"\"Calculate evaluation metrics for ML model\n",
    "    \n",
    "    Args:\n",
    "    actual: array. Array containing actual labels.\n",
    "    predicted: array. Array containing predicted labels.\n",
    "    col_names: list of strings. List containing names for each of the predicted fields.\n",
    "       \n",
    "    Returns:\n",
    "    metrics_df: dataframe. Dataframe containing the accuracy, precision, recall \n",
    "    and f1 score for a given set of actual and predicted labels.\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    # Calculate evaluation metrics for each set of labels\n",
    "    for i in range(len(col_names)):\n",
    "        accuracy = accuracy_score(actual[:, i], predicted[:, i])\n",
    "        precision = precision_score(actual[:, i], predicted[:, i])\n",
    "        recall = recall_score(actual[:, i], predicted[:, i])\n",
    "        f1 = f1_score(actual[:, i], predicted[:, i])\n",
    "        \n",
    "        metrics.append([accuracy, precision, recall, f1])\n",
    "    \n",
    "    # Create dataframe containing metrics\n",
    "    metrics = np.array(metrics)\n",
    "    metrics_df = pd.DataFrame(data = metrics, index = col_names, columns = ['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "      \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.990267   0.992651  0.994645  0.993647\n",
      "request                 0.987603   0.997442  0.930233  0.962666\n",
      "offer                   0.998617   1.000000  0.715789  0.834356\n",
      "aid_related             0.984325   0.994847  0.967608  0.981039\n",
      "medical_help            0.988935   0.999260  0.862620  0.925926\n",
      "medical_products        0.992367   0.998817  0.850806  0.918889\n",
      "search_and_rescue       0.993955   0.995624  0.796848  0.885214\n",
      "security                0.995543   1.000000  0.749280  0.856672\n",
      "military                0.994980   0.996317  0.849294  0.916949\n",
      "child_alone             1.000000   0.000000  0.000000  0.000000\n",
      "water                   0.995287   1.000000  0.926752  0.961983\n",
      "food                    0.995236   0.999052  0.958618  0.978417\n",
      "shelter                 0.993033   0.997511  0.923919  0.959306\n",
      "clothing                0.997080   0.996047  0.818182  0.898396\n",
      "money                   0.995441   1.000000  0.807775  0.893668\n",
      "missing_people          0.998207   1.000000  0.837963  0.911839\n",
      "refugees                0.994724   1.000000  0.837539  0.911588\n",
      "death                   0.994980   0.997522  0.893452  0.942623\n",
      "other_aid               0.978485   0.997239  0.839597  0.911653\n",
      "infrastructure_related  0.987706   0.999032  0.811959  0.895833\n",
      "transport               0.989703   0.998578  0.778271  0.874766\n",
      "buildings               0.992009   0.997628  0.845226  0.915125\n",
      "electricity             0.996517   1.000000  0.831683  0.908108\n",
      "tools                   0.998258   1.000000  0.721311  0.838095\n",
      "hospitals               0.996209   1.000000  0.668161  0.801075\n",
      "shops                   0.998258   1.000000  0.609195  0.757143\n",
      "aid_centers             0.996517   1.000000  0.708155  0.829146\n",
      "other_infrastructure    0.989960   0.995468  0.773474  0.870542\n",
      "weather_related         0.987552   0.996375  0.958876  0.977266\n",
      "floods                  0.992162   0.999321  0.906346  0.950565\n",
      "storm                   0.994724   0.994801  0.948238  0.970961\n",
      "fire                    0.997439   1.000000  0.775785  0.873737\n",
      "earthquake              0.995799   0.994819  0.959467  0.976823\n",
      "cold                    0.997285   1.000000  0.864796  0.927497\n",
      "other_weather           0.989447   0.998791  0.801164  0.889128\n",
      "direct_report           0.979304   0.996475  0.896406  0.943795\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for training set\n",
    "Y_train_pred = pipeline.predict(X_train)\n",
    "col_names = list(Y.columns.values)\n",
    "\n",
    "print(get_eval_metrics(np.array(Y_train), Y_train_pred, col_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.805133   0.846543  0.909603  0.876941\n",
      "request                 0.887967   0.795764  0.469643  0.590679\n",
      "offer                   0.996465   0.000000  0.000000  0.000000\n",
      "aid_related             0.744275   0.734845  0.592758  0.656198\n",
      "medical_help            0.920240   0.500000  0.067437  0.118846\n",
      "medical_products        0.953896   0.666667  0.130841  0.218750\n",
      "search_and_rescue       0.976026   0.363636  0.026144  0.048780\n",
      "security                0.980636   0.000000  0.000000  0.000000\n",
      "military                0.966959   0.785714  0.049327  0.092827\n",
      "child_alone             1.000000   0.000000  0.000000  0.000000\n",
      "water                   0.955125   0.840659  0.367788  0.511706\n",
      "food                    0.935454   0.790076  0.571823  0.663462\n",
      "shelter                 0.936530   0.809701  0.374784  0.512397\n",
      "clothing                0.986015   0.875000  0.072165  0.133333\n",
      "money                   0.978331   0.500000  0.042553  0.078431\n",
      "missing_people          0.987245   0.000000  0.000000  0.000000\n",
      "refugees                0.964653   0.720000  0.074689  0.135338\n",
      "death                   0.958353   0.750000  0.112628  0.195846\n",
      "other_aid               0.866913   0.494737  0.054335  0.097917\n",
      "infrastructure_related  0.931919   0.090909  0.002304  0.004494\n",
      "transport               0.954511   0.555556  0.050167  0.092025\n",
      "buildings               0.952052   0.716667  0.127219  0.216080\n",
      "electricity             0.980175   0.454545  0.039062  0.071942\n",
      "tools                   0.994314   0.000000  0.000000  0.000000\n",
      "hospitals               0.990472   0.000000  0.000000  0.000000\n",
      "shops                   0.994929   0.000000  0.000000  0.000000\n",
      "aid_centers             0.988320   0.000000  0.000000  0.000000\n",
      "other_infrastructure    0.953896   0.333333  0.003344  0.006623\n",
      "weather_related         0.850930   0.837423  0.590270  0.692454\n",
      "floods                  0.949132   0.879245  0.437970  0.584693\n",
      "storm                   0.932842   0.789634  0.413078  0.542408\n",
      "fire                    0.991087   0.666667  0.033898  0.064516\n",
      "earthquake              0.962348   0.894027  0.709480  0.791134\n",
      "cold                    0.980483   0.823529  0.101449  0.180645\n",
      "other_weather           0.947595   0.550000  0.063768  0.114286\n",
      "direct_report           0.840018   0.717770  0.319132  0.441823\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for test set\n",
    "Y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "eval_metrics0 = get_eval_metrics(np.array(Y_test), Y_test_pred, col_names)\n",
    "print(eval_metrics0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metric(y_true, y_pred):\n",
    "    \"\"\"Calculate median F1 score for all of the output classifiers\n",
    "    \n",
    "    Args:\n",
    "    y_true: array. Array containing actual labels.\n",
    "    y_pred: array. Array containing predicted labels.\n",
    "        \n",
    "    Returns:\n",
    "    score: float. Median F1 score for all of the output classifiers\n",
    "    \"\"\"\n",
    "    f1_list = []\n",
    "    for i in range(np.shape(y_pred)[1]):\n",
    "        f1 = f1_score(np.array(y_true)[:, i], y_pred[:, i])\n",
    "        f1_list.append(f1)\n",
    "        \n",
    "    score = np.median(f1_list)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.12098569157392688, total=  57.0s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.1096531566149698, total=  56.6s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  2.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.11998892580287929, total=  57.5s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  3.7min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.1381876697173891, total=  47.6s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  4.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.17217528778222418, total=  47.7s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  5.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.13148199318412085, total=  47.6s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  7.0min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.13415470991890205, total=  57.9s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  8.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.13159752868490732, total=  58.2s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  9.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.11274412446209864, total=  58.0s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed: 10.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.15023763421932756, total=  46.9s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.1914808823874159, total=  46.8s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.11233132776447223, total=  47.1s\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.13422925620210563, total= 1.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.11549093321539142, total= 1.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.11816043283933192, total= 1.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.1984382596013612, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.1765778081567555, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.13723298559364133, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.12035123966942149, total= 1.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.09921709226604229, total= 1.8min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.11092595928661501, total= 1.9min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.1793943836181227, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.19636515979731078, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=2, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.1479152261477506, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.13535555873515526, total=  50.7s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.13273167510455647, total=  50.1s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.1300327034883721, total=  50.7s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.24450992837065916, total=  44.6s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.1928888888888889, total=  44.3s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.2038122079655863, total=  44.7s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.13229056203605513, total=  50.6s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.13094528104964964, total=  50.3s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.09571784232365146, total=  50.4s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.18922417451829218, total=  43.6s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.19013392857142855, total=  43.5s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.20115610568313907, total=  43.7s\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.12663864348817327, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.11223162003903708, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.08691253951527923, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.2076021249313061, total= 1.3min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.18494226959076315, total= 1.3min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.16817238089893943, total= 1.3min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.11679571173317452, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.12340789064926994, total= 1.5min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.06246697260464469, total= 1.6min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.18953822965195946, total= 1.3min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.16109240553685, total= 1.3min\n",
      "[CV] clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=5, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.13348164627363737, total= 1.3min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.12299997158041323, total=  47.8s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.11274717514124294, total=  47.2s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=1, score=0.11733333333333333, total=  47.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.19243526413939385, total=  43.5s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.24611904904246626, total=  43.1s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=True, vect__min_df=5, score=0.18473426094890508, total=  43.6s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.12774032742310087, total=  47.1s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.148175204699723, total=  46.9s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=1, score=0.11930421629797694, total=  47.5s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.2573614513437711, total=  44.3s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.16645442968892124, total=  42.1s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=10, tfidf__use_idf=False, vect__min_df=5, score=0.16232322080291972, total=  42.0s\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.10388020509908982, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.11314685314685315, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=1, score=0.07263122017723245, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.17346832272205406, total= 1.3min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.17877723962878822, total= 1.2min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=True, vect__min_df=5, score=0.1304755598199927, total= 1.3min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.09592162223741171, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.10622685502674531, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=1, score=0.07728606306805358, total= 1.4min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.19934143870314083, total= 1.2min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.17175032962253123, total= 1.2min\n",
      "[CV] clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5 \n",
      "[CV]  clf__estimator__min_samples_split=10, clf__estimator__n_estimators=25, tfidf__use_idf=False, vect__min_df=5, score=0.1537369075093201, total= 1.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  72 out of  72 | elapsed: 104.6min finished\n"
     ]
    }
   ],
   "source": [
    "# Create grid search object\n",
    "\n",
    "parameters = {'vect__min_df': [1, 5],\n",
    "              'tfidf__use_idf':[True, False],\n",
    "              'clf__estimator__n_estimators':[10, 25], \n",
    "              'clf__estimator__min_samples_split':[2, 5, 10]}\n",
    "\n",
    "scorer = make_scorer(performance_metric)\n",
    "cv = GridSearchCV(pipeline, param_grid = parameters, scoring = scorer, verbose = 10)\n",
    "\n",
    "# Find best parameters\n",
    "np.random.seed(81)\n",
    "tuned_model = cv.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 48.15504932,  39.09357142,  49.15161029,  38.48047558,\n",
       "         98.05366484,  75.7603395 ,  99.53477033,  74.21120564,\n",
       "         41.60310356,  36.076449  ,  41.52534389,  35.08816942,\n",
       "         82.18089588,  68.16823459,  82.47009039,  66.05912336,\n",
       "         38.58997726,  34.91165304,  38.32893236,  34.3769989 ,\n",
       "         74.49657448,  64.73617379,  73.63223131,  61.9577775 ]),\n",
       " 'std_fit_time': array([ 0.4631399 ,  0.07616295,  0.10756875,  0.19369545,  1.32067181,\n",
       "         1.0362167 ,  0.93384645,  0.35722905,  0.33026342,  0.23388637,\n",
       "         0.24222969,  0.12655659,  0.83421525,  0.26910238,  2.11272121,\n",
       "         1.17146851,  0.28813232,  0.28537981,  0.26385333,  1.09602598,\n",
       "         0.25679854,  0.34076685,  0.53196102,  0.31639609]),\n",
       " 'mean_score_time': array([  8.88071521,   8.52152395,   8.86455639,   8.44155161,\n",
       "         11.25332157,  10.32208618,  11.15933768,  10.184841  ,\n",
       "          8.88459953,   8.47370084,   8.8959442 ,   8.49980418,\n",
       "         11.22818033,  10.27406653,  11.21623619,  10.20748091,\n",
       "          8.85822972,   8.48157032,   8.82834959,   8.44495893,\n",
       "         11.2064201 ,  10.20269831,  11.09294581,  10.09454354]),\n",
       " 'std_score_time': array([ 0.08754217,  0.11914295,  0.08875866,  0.10427571,  0.07280949,\n",
       "         0.0961457 ,  0.13664045,  0.11979385,  0.0805501 ,  0.07630683,\n",
       "         0.1157913 ,  0.06079721,  0.11633318,  0.11057286,  0.1033644 ,\n",
       "         0.15650968,  0.08720512,  0.09728492,  0.09204194,  0.10162528,\n",
       "         0.15022199,  0.07204073,  0.07935136,  0.0871808 ]),\n",
       " 'param_clf__estimator__min_samples_split': masked_array(data = [2 2 2 2 2 2 2 2 5 5 5 5 5 5 5 5 10 10 10 10 10 10 10 10],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_clf__estimator__n_estimators': masked_array(data = [10 10 10 10 25 25 25 25 10 10 10 10 25 25 25 25 10 10 10 10 25 25 25 25],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_tfidf__use_idf': masked_array(data = [True True False False True True False False True True False False True\n",
       "  True False False True True False False True True False False],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'param_vect__min_df': masked_array(data = [1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5 1 5],\n",
       "              mask = [False False False False False False False False False False False False\n",
       "  False False False False False False False False False False False False],\n",
       "        fill_value = ?),\n",
       " 'params': [{'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 2,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 5,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 10,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': True,\n",
       "   'vect__min_df': 5},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 1},\n",
       "  {'clf__estimator__min_samples_split': 10,\n",
       "   'clf__estimator__n_estimators': 25,\n",
       "   'tfidf__use_idf': False,\n",
       "   'vect__min_df': 5}],\n",
       " 'split0_test_score': array([ 0.12098569,  0.13818767,  0.13415471,  0.15023763,  0.13422926,\n",
       "         0.19843826,  0.12035124,  0.17939438,  0.13535556,  0.24450993,\n",
       "         0.13229056,  0.18922417,  0.12663864,  0.20760212,  0.11679571,\n",
       "         0.18953823,  0.12299997,  0.19243526,  0.12774033,  0.25736145,\n",
       "         0.10388021,  0.17346832,  0.09592162,  0.19934144]),\n",
       " 'split1_test_score': array([ 0.10965316,  0.17217529,  0.13159753,  0.19148088,  0.11549093,\n",
       "         0.17657781,  0.09921709,  0.19636516,  0.13273168,  0.19288889,\n",
       "         0.13094528,  0.19013393,  0.11223162,  0.18494227,  0.12340789,\n",
       "         0.16109241,  0.11274718,  0.24611905,  0.1481752 ,  0.16645443,\n",
       "         0.11314685,  0.17877724,  0.10622686,  0.17175033]),\n",
       " 'split2_test_score': array([ 0.11998893,  0.13148199,  0.11274412,  0.11233133,  0.11816043,\n",
       "         0.13723299,  0.11092596,  0.14791523,  0.1300327 ,  0.20381221,\n",
       "         0.09571784,  0.20115611,  0.08691254,  0.16817238,  0.06246697,\n",
       "         0.13348165,  0.11733333,  0.18473426,  0.11930422,  0.16232322,\n",
       "         0.07263122,  0.13047556,  0.07728606,  0.15373691]),\n",
       " 'mean_test_score': array([ 0.11687592,  0.14728165,  0.12616545,  0.15134995,  0.12262687,\n",
       "         0.17074968,  0.11016476,  0.17455826,  0.13270665,  0.21373701,\n",
       "         0.11965123,  0.19350474,  0.10859427,  0.18690559,  0.10089019,\n",
       "         0.16137076,  0.11769349,  0.20776286,  0.13173992,  0.1953797 ,\n",
       "         0.09655276,  0.16090704,  0.09314485,  0.17494289]),\n",
       " 'std_test_score': array([ 0.00512345,  0.01781407,  0.00954756,  0.03232224,  0.00827619,\n",
       "         0.02532452,  0.00864475,  0.02007304,  0.00217312,  0.022212  ,\n",
       "         0.01693237,  0.00542307,  0.01642079,  0.01615688,  0.02730309,\n",
       "         0.02288585,  0.00419343,  0.02730353,  0.01212108,  0.04386015,\n",
       "         0.01733297,  0.02162718,  0.01197707,  0.01875434]),\n",
       " 'rank_test_score': array([19, 12, 15, 11, 16,  8, 20,  7, 13,  1, 17,  4, 21,  5, 22,  9, 18,\n",
       "         2, 14,  3, 23, 10, 24,  6], dtype=int32),\n",
       " 'split0_train_score': array([ 0.91592243,  0.91289223,  0.91175088,  0.91487177,  0.98437011,\n",
       "         0.98688215,  0.98288897,  0.98341231,  0.85673378,  0.83357366,\n",
       "         0.83621221,  0.82771196,  0.91046246,  0.87188555,  0.87665404,\n",
       "         0.86300942,  0.77520023,  0.76664373,  0.79137792,  0.72472653,\n",
       "         0.81390884,  0.80313628,  0.80807116,  0.78348241]),\n",
       " 'split1_train_score': array([ 0.91549583,  0.91919172,  0.91382539,  0.92440931,  0.98179445,\n",
       "         0.98640702,  0.98376716,  0.98196795,  0.86281218,  0.84324087,\n",
       "         0.83234363,  0.83072073,  0.87963554,  0.86461634,  0.87819735,\n",
       "         0.85791925,  0.79616405,  0.7866901 ,  0.76414634,  0.73450478,\n",
       "         0.82987616,  0.77880435,  0.7991281 ,  0.78019324]),\n",
       " 'split2_train_score': array([ 0.91270932,  0.91615001,  0.91125017,  0.91143205,  0.9831607 ,\n",
       "         0.98258661,  0.98357667,  0.98367646,  0.84953572,  0.82415457,\n",
       "         0.84677849,  0.83416969,  0.89294411,  0.87303941,  0.8802268 ,\n",
       "         0.85009735,  0.80173909,  0.75419596,  0.77511973,  0.7345772 ,\n",
       "         0.82172137,  0.75897583,  0.78905715,  0.77217486]),\n",
       " 'mean_train_score': array([ 0.91470919,  0.91607799,  0.91227548,  0.91690438,  0.98310842,\n",
       "         0.98529193,  0.98341093,  0.9830189 ,  0.85636056,  0.83365637,\n",
       "         0.83844477,  0.83086746,  0.89434737,  0.8698471 ,  0.87835939,\n",
       "         0.85700867,  0.79103446,  0.7691766 ,  0.77688133,  0.7312695 ,\n",
       "         0.82183546,  0.78030548,  0.79875214,  0.77861684]),\n",
       " 'std_train_score': array([ 0.00142481,  0.00257226,  0.00111485,  0.00548944,  0.00105216,\n",
       "         0.00192276,  0.00037719,  0.00075092,  0.00542651,  0.00779217,\n",
       "         0.0061008 ,  0.0026384 ,  0.0126241 ,  0.00372858,  0.00146307,\n",
       "         0.00531051,  0.01142548,  0.01338603,  0.01118681,  0.00462668,\n",
       "         0.00651913,  0.01805965,  0.00776699,  0.00474896])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get results of grid search\n",
    "tuned_model.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21373700840837814"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best mean test score\n",
    "np.max(tuned_model.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__min_samples_split': 5,\n",
       " 'clf__estimator__n_estimators': 10,\n",
       " 'tfidf__use_idf': True,\n",
       " 'vect__min_df': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parameters for best mean test score\n",
    "tuned_model.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Accuracy  Precision    Recall        F1\n",
      "related                 0.809897   0.840328  0.927119  0.881593\n",
      "request                 0.890887   0.777027  0.513393  0.618280\n",
      "offer                   0.996465   0.000000  0.000000  0.000000\n",
      "aid_related             0.757953   0.711171  0.693916  0.702437\n",
      "medical_help            0.919932   0.492424  0.125241  0.199693\n",
      "medical_products        0.956816   0.727273  0.199377  0.312958\n",
      "search_and_rescue       0.978177   0.657143  0.150327  0.244681\n",
      "security                0.980636   0.250000  0.008065  0.015625\n",
      "military                0.966651   0.562500  0.121076  0.199262\n",
      "child_alone             1.000000   0.000000  0.000000  0.000000\n",
      "water                   0.963885   0.813149  0.564904  0.666667\n",
      "food                    0.941448   0.788235  0.647790  0.711145\n",
      "shelter                 0.934993   0.763514  0.390328  0.516571\n",
      "clothing                0.986783   0.641026  0.257732  0.367647\n",
      "money                   0.978638   0.562500  0.063830  0.114650\n",
      "missing_people          0.987552   0.600000  0.036585  0.068966\n",
      "refugees                0.964346   0.621622  0.095436  0.165468\n",
      "death                   0.962656   0.727273  0.273038  0.397022\n",
      "other_aid               0.868142   0.527559  0.077457  0.135081\n",
      "infrastructure_related  0.931151   0.150000  0.006912  0.013216\n",
      "transport               0.952820   0.420000  0.070234  0.120344\n",
      "buildings               0.952205   0.670886  0.156805  0.254197\n",
      "electricity             0.980790   0.714286  0.039062  0.074074\n",
      "tools                   0.994314   0.000000  0.000000  0.000000\n",
      "hospitals               0.990779   0.000000  0.000000  0.000000\n",
      "shops                   0.994929   0.000000  0.000000  0.000000\n",
      "aid_centers             0.988167   0.000000  0.000000  0.000000\n",
      "other_infrastructure    0.952359   0.133333  0.006689  0.012739\n",
      "weather_related         0.870601   0.821429  0.696216  0.753657\n",
      "floods                  0.954511   0.866460  0.524436  0.653396\n",
      "storm                   0.934532   0.725843  0.515152  0.602612\n",
      "fire                    0.991240   0.750000  0.050847  0.095238\n",
      "earthquake              0.968342   0.883562  0.788991  0.833603\n",
      "cold                    0.980636   0.800000  0.115942  0.202532\n",
      "other_weather           0.947288   0.519231  0.078261  0.136020\n",
      "direct_report           0.844321   0.695225  0.383424  0.494259\n"
     ]
    }
   ],
   "source": [
    "# Calculate evaluation metrics for test set\n",
    "tuned_pred_test = tuned_model.predict(X_test)\n",
    "\n",
    "eval_metrics1 = get_eval_metrics(np.array(Y_test), tuned_pred_test, col_names)\n",
    "\n",
    "print(eval_metrics1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.944312</td>\n",
       "      <td>0.521740</td>\n",
       "      <td>0.189102</td>\n",
       "      <td>0.242627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.058039</td>\n",
       "      <td>0.331568</td>\n",
       "      <td>0.246085</td>\n",
       "      <td>0.272760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.744275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.934801</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.006090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.956739</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.065603</td>\n",
       "      <td>0.116566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.981981</td>\n",
       "      <td>0.791498</td>\n",
       "      <td>0.369537</td>\n",
       "      <td>0.511878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894027</td>\n",
       "      <td>0.909603</td>\n",
       "      <td>0.876941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall         F1\n",
       "count  36.000000  36.000000  36.000000  36.000000\n",
       "mean    0.944312   0.521740   0.189102   0.242627\n",
       "std     0.058039   0.331568   0.246085   0.272760\n",
       "min     0.744275   0.000000   0.000000   0.000000\n",
       "25%     0.934801   0.272727   0.003084   0.006090\n",
       "50%     0.956739   0.666667   0.065603   0.116566\n",
       "75%     0.981981   0.791498   0.369537   0.511878\n",
       "max     1.000000   0.894027   0.909603   0.876941"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary stats for first model\n",
    "eval_metrics0.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>36.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.946523</td>\n",
       "      <td>0.533694</td>\n",
       "      <td>0.238294</td>\n",
       "      <td>0.293434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.055413</td>\n",
       "      <td>0.300279</td>\n",
       "      <td>0.270117</td>\n",
       "      <td>0.283594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.757953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.934878</td>\n",
       "      <td>0.377500</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>0.055630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.963270</td>\n",
       "      <td>0.649084</td>\n",
       "      <td>0.118509</td>\n",
       "      <td>0.199477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.982288</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>0.421094</td>\n",
       "      <td>0.538082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.883562</td>\n",
       "      <td>0.927119</td>\n",
       "      <td>0.881593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Accuracy  Precision     Recall         F1\n",
       "count  36.000000  36.000000  36.000000  36.000000\n",
       "mean    0.946523   0.533694   0.238294   0.293434\n",
       "std     0.055413   0.300279   0.270117   0.283594\n",
       "min     0.757953   0.000000   0.000000   0.000000\n",
       "25%     0.934878   0.377500   0.029455   0.055630\n",
       "50%     0.963270   0.649084   0.118509   0.199477\n",
       "75%     0.982288   0.753378   0.421094   0.538082\n",
       "max     1.000000   0.883562   0.927119   0.881593"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get summary stats for tuned model\n",
    "eval_metrics1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "[CV] clf__estimator__C=1, clf__estimator__degree=1, clf__estimator__kernel=poly, tfidf__use_idf=True, vect__min_df=5 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-52ed2b4c89f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Find best parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m81\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtuned_model2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    168\u001b[0m             delayed(_fit_estimator)(\n\u001b[1;32m    169\u001b[0m                 self.estimator, X, y[:, i], sample_weight)\n\u001b[0;32m--> 170\u001b[0;31m             for i in range(y.shape[1]))\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/multioutput.py\u001b[0m in \u001b[0;36m_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    504\u001b[0m             raise ValueError(\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one; got %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                 % len(cls))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1"
     ]
    }
   ],
   "source": [
    "# Try using SVM instead of Random Forest Classifier\n",
    "pipeline2 = Pipeline([\n",
    "    ('vect', CountVectorizer(tokenizer = tokenize)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultiOutputClassifier(SVC()))\n",
    "])\n",
    "\n",
    "parameters2 = {'vect__min_df': [5],\n",
    "              'tfidf__use_idf':[True],\n",
    "              'clf__estimator__kernel': ['poly'], \n",
    "              'clf__estimator__degree': [1, 2, 3],\n",
    "              'clf__estimator__C':[1, 10, 100]}\n",
    "\n",
    "cv2 = GridSearchCV(pipeline2, param_grid = parameters2, scoring = scorer, verbose = 10)\n",
    "\n",
    "# Find best parameters\n",
    "np.random.seed(81)\n",
    "tuned_model2 = cv2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results of grid search\n",
    "tuned_model2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tuned_model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-b6b939155403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtuned_pred_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuned_model2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meval_metrics2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_eval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_pred_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_metrics2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tuned_model2' is not defined"
     ]
    }
   ],
   "source": [
    "tuned_pred_test2 = tuned_model2.predict(X_test)\n",
    "\n",
    "eval_metrics2 = get_eval_metrics(np.array(Y_test), tuned_pred_test2, col_names)\n",
    "\n",
    "print(eval_metrics2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function tokenize at 0x7f63ea20c950>: it's not the same object as __main__.tokenize",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-8f74c1df5cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuned_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disaster_model.sav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <function tokenize at 0x7f63ea20c950>: it's not the same object as __main__.tokenize"
     ]
    }
   ],
   "source": [
    "pickle.dump(tuned_model, open('disaster_model.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
